# Ansvar MCP Server Skeleton

> **The definitive template for building MCP servers in the Ansvar ecosystem**

```
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                               â•‘
    â•‘     ___              _____                 __                 â•‘
    â•‘    /   |  ____  ____/ ___/____  ____ _____/ /_____  _____     â•‘
    â•‘   / /| | / __ \/ ___\__ \/ __ \/ __ `/ __  / ___/ / / / /     â•‘
    â•‘  / ___ |/ / / (__  )__/ / /_/ / /_/ / /_/ (__  ) /_/ / /      â•‘
    â•‘ /_/  |_/_/ /_/____/____/\____/\__,_/\__,_/____/\__, /_/       â•‘
    â•‘                                               /____/          â•‘
    â•‘                                                               â•‘
    â•‘            MCP SERVER SKELETON TEMPLATE                       â•‘
    â•‘            Version 1.0 | January 2026                         â•‘
    â•‘                                                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Quick Start](#quick-start)
4. [Detailed Setup Guide](#detailed-setup-guide)
5. [File Reference](#file-reference)
6. [Tool Development Guide](#tool-development-guide)
7. [Database Design](#database-design)
8. [Data Ingestion](#data-ingestion)
9. [Testing Strategy](#testing-strategy)
10. [Deployment](#deployment)
11. [Checklist](#checklist)

---

## Overview

### What Is This?

This skeleton provides a **production-ready template** for creating MCP (Model Context Protocol) servers that provide AI assistants with access to structured legal, regulatory, or reference data.

### Designed For

| Server | Package | Status |
|--------|---------|--------|
| ğŸ‡ªğŸ‡º EU Regulations | `@ansvar/eu-regulations-mcp` | âœ… Live |
| ğŸ‡¸ğŸ‡ª Swedish Law | `@ansvar/swedish-law-mcp` | ğŸ“‹ Planned |
| ğŸ‡³ğŸ‡´ğŸ‡©ğŸ‡°ğŸ‡«ğŸ‡® Nordic Law | `@ansvar/nordic-law-mcp` | ğŸ“‹ Planned |

### Core Principles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DESIGN PRINCIPLES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. OFFLINE-FIRST                                               â”‚
â”‚     â””â”€ All data embedded in SQLite, no runtime API calls        â”‚
â”‚                                                                 â”‚
â”‚  2. FULL-TEXT SEARCH                                            â”‚
â”‚     â””â”€ SQLite FTS5 for fast, relevant search                    â”‚
â”‚                                                                 â”‚
â”‚  3. TYPE-SAFE                                                   â”‚
â”‚     â””â”€ TypeScript interfaces for all inputs/outputs             â”‚
â”‚                                                                 â”‚
â”‚  4. WELL-TESTED                                                 â”‚
â”‚     â””â”€ In-memory test database, comprehensive coverage          â”‚
â”‚                                                                 â”‚
â”‚  5. EASY DEPLOYMENT                                             â”‚
â”‚     â””â”€ npm, Docker, or direct invocation                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MCP SERVER ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  â”‚  stdio  â”‚                  â”‚
    â”‚   AI Assistant   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   MCP Server     â”‚
    â”‚  (Claude, etc.)  â”‚  JSON   â”‚   (this code)    â”‚
    â”‚                  â”‚         â”‚                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â”‚ SQL queries
                                          â–¼
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚                  â”‚
                                 â”‚     SQLite DB    â”‚
                                 â”‚  (embedded data) â”‚
                                 â”‚                  â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ DATA PIPELINE (Build Time)                                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                             â”‚
    â”‚  Source          Ingest Script       Seed JSON      DB      â”‚
    â”‚  â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€      â”‚
    â”‚                                                             â”‚
    â”‚  EUR-Lex    â”€â”€â”€â–º ingest-eurlex.ts â”€â”€â–º gdpr.json            â”‚
    â”‚  lagen.nu   â”€â”€â”€â–º ingest-sfs.ts    â”€â”€â–º brottsbalken.json    â”‚
    â”‚  lovdata.no â”€â”€â”€â–º ingest-norway.ts â”€â”€â–º sikkerhetsloven.json â”‚
    â”‚                                                    â”‚        â”‚
    â”‚                                                    â–¼        â”‚
    â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚                       build-db.ts â—„â”€â”€â”€â”€â”€â”€â”€ â”‚ seed/*.jsonâ”‚   â”‚
    â”‚                            â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                            â–¼                                â”‚
    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
    â”‚                    â”‚ database.db  â”‚                         â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
    â”‚                                                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
your-mcp-server/
â”‚
â”œâ”€â”€ ğŸ“ src/                          # TypeScript source code
â”‚   â”œâ”€â”€ ğŸ“„ index.ts                  # MCP server entry point
â”‚   â””â”€â”€ ğŸ“ tools/                    # Tool implementations
â”‚       â”œâ”€â”€ ğŸ“„ search.ts             # Full-text search tool
â”‚       â”œâ”€â”€ ğŸ“„ get-item.ts           # Get specific item tool
â”‚       â”œâ”€â”€ ğŸ“„ list.ts               # List/browse tool
â”‚       â””â”€â”€ ğŸ“„ ...                   # Additional tools
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Build and data scripts
â”‚   â”œâ”€â”€ ğŸ“„ build-db.ts               # Build SQLite from seed JSON
â”‚   â”œâ”€â”€ ğŸ“„ ingest-source.ts          # Scrape/fetch source data
â”‚   â””â”€â”€ ğŸ“„ check-updates.ts          # Monitor for source updates
â”‚
â”œâ”€â”€ ğŸ“ tests/                        # Test suite
â”‚   â”œâ”€â”€ ğŸ“ fixtures/
â”‚   â”‚   â””â”€â”€ ğŸ“„ test-db.ts            # In-memory test database
â”‚   â””â”€â”€ ğŸ“ tools/
â”‚       â”œâ”€â”€ ğŸ“„ search.test.ts        # Tool tests
â”‚       â””â”€â”€ ğŸ“„ ...
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Data files
â”‚   â”œâ”€â”€ ğŸ“„ database.db               # Pre-built SQLite database
â”‚   â””â”€â”€ ğŸ“ seed/                     # Source JSON files
â”‚       â”œâ”€â”€ ğŸ“„ item1.json
â”‚       â”œâ”€â”€ ğŸ“„ item2.json
â”‚       â”œâ”€â”€ ğŸ“ mappings/             # Cross-reference mappings
â”‚       â””â”€â”€ ğŸ“ applicability/        # Applicability rules
â”‚
â”œâ”€â”€ ğŸ“ .github/
â”‚   â””â”€â”€ ğŸ“ workflows/
â”‚       â””â”€â”€ ğŸ“„ publish.yml           # NPM publish workflow
â”‚
â”œâ”€â”€ ğŸ“„ package.json                  # Dependencies and scripts
â”œâ”€â”€ ğŸ“„ tsconfig.json                 # TypeScript configuration
â”œâ”€â”€ ğŸ“„ vitest.config.ts              # Test configuration
â”œâ”€â”€ ğŸ“„ Dockerfile                    # Docker build
â”œâ”€â”€ ğŸ“„ smithery.yaml                 # Smithery registry
â”œâ”€â”€ ğŸ“„ README.md                     # User documentation
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md               # Contributor guidelines
â”œâ”€â”€ ğŸ“„ COVERAGE.md                   # Data coverage tracking
â””â”€â”€ ğŸ“„ LICENSE                       # Apache 2.0
```

---

## Quick Start

### 1. Copy the Skeleton

```bash
# From the EU_compliance_MCP repository
cp -r skeleton/ ../your-new-mcp-server/
cd ../your-new-mcp-server/

# Or use degit for a clean copy
npx degit ansvar-systems/eu-regulations-mcp/skeleton your-new-mcp-server
```

### 2. Customize package.json

```bash
# Update these fields in package.json:
# - name: "@ansvar/your-mcp-server"
# - description: "Your server description"
# - repository: Your GitHub URL
# - keywords: Relevant keywords
```

### 3. Define Your Data Model

Edit `scripts/build-db.ts` to define your schema:

```typescript
// Example for Swedish law:
const SCHEMA = `
  CREATE TABLE statutes (
    id TEXT PRIMARY KEY,
    sfs_number TEXT UNIQUE,      -- e.g., "2018:218"
    short_cite TEXT,             -- e.g., "DSL"
    full_name TEXT,
    effective_date TEXT
  );

  CREATE TABLE sections (
    rowid INTEGER PRIMARY KEY,
    statute TEXT REFERENCES statutes(id),
    chapter TEXT,
    section_number TEXT,
    text TEXT,
    UNIQUE(statute, chapter, section_number)
  );

  -- FTS5 for full-text search
  CREATE VIRTUAL TABLE sections_fts USING fts5(
    statute, chapter, section_number, text,
    content='sections',
    content_rowid='rowid'
  );
`;
```

### 4. Implement Your Tools

Create tools in `src/tools/`:

```typescript
// src/tools/search.ts
export interface SearchInput {
  query: string;
  statutes?: string[];
  limit?: number;
}

export async function searchStatutes(
  db: Database,
  input: SearchInput
): Promise<SearchResult[]> {
  // Implementation
}
```

### 5. Wire Up the Server

Register tools in `src/index.ts`:

```typescript
server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: [
    {
      name: 'search_statutes',
      description: 'Search Swedish statutes by keyword',
      inputSchema: { /* ... */ }
    }
  ]
}));
```

### 6. Build and Test

```bash
npm install
npm run build:db    # Build database from seed data
npm run build       # Compile TypeScript
npm test            # Run tests
npm run dev         # Test with MCP inspector
```

---

## Detailed Setup Guide

### Step 1: Initialize the Project

```bash
# Create directory and initialize
mkdir @ansvar/your-mcp-server
cd @ansvar/your-mcp-server
npm init -y

# Install dependencies
npm install @modelcontextprotocol/sdk better-sqlite3
npm install -D typescript vitest tsx @types/node @types/better-sqlite3

# Copy skeleton files
cp -r /path/to/skeleton/* .
```

### Step 2: Configure TypeScript

The provided `tsconfig.json` is pre-configured:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "skipLibCheck": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "tests"]
}
```

### Step 3: Design Your Data Model

Ask yourself:

1. **What entities am I storing?**
   - EU Regulations: regulations, articles, definitions
   - Swedish Law: statutes, sections, cases, propositions
   - Nordic Law: countries, statutes, sections

2. **What relationships exist?**
   - One-to-many: statute â†’ sections
   - Many-to-many: controls â†” articles (via mappings)

3. **What needs full-text search?**
   - Usually: main text content
   - Create FTS5 virtual tables for searchable content

### Step 4: Create Seed Data Format

Define your JSON seed format:

```typescript
// Swedish law example
interface StatuteSeed {
  id: string;           // "DSL"
  sfs_number: string;   // "2018:218"
  short_cite: string;   // "Dataskyddslagen"
  full_name: string;    // "Lag (2018:218) med kompletterande..."
  effective_date: string;

  chapters: Array<{
    number: string;     // "1"
    title: string;      // "Lagens syfte och tillÃ¤mpningsomrÃ¥de"
    sections: Array<{
      number: string;   // "1"
      text: string;
      effective_from?: string;
    }>;
  }>;

  definitions?: Array<{
    term: string;
    definition: string;
    section: string;    // Reference to defining section
  }>;
}
```

### Step 5: Implement Data Ingestion

Create a script to fetch and parse source data:

```typescript
// scripts/ingest-sfs.ts
import { JSDOM } from 'jsdom';
import fs from 'fs';

async function ingestStatute(sfsNumber: string, outputPath: string) {
  // 1. Fetch HTML from lagen.nu or riksdagen.se
  const url = `https://lagen.nu/${sfsNumber.replace(':', '_')}`;
  const response = await fetch(url);
  const html = await response.text();

  // 2. Parse HTML to DOM
  const dom = new JSDOM(html);
  const document = dom.window.document;

  // 3. Extract structured data
  const statute: StatuteSeed = {
    id: extractShortCite(document),
    sfs_number: sfsNumber,
    // ... extract other fields
  };

  // 4. Write seed JSON
  fs.writeFileSync(outputPath, JSON.stringify(statute, null, 2));
  console.log(`âœ“ Saved ${outputPath}`);
}
```

### Step 6: Build the Database

The `build-db.ts` script:

1. Creates fresh SQLite database
2. Runs schema creation
3. Loads all seed JSON files
4. Inserts data with proper relationships
5. Creates FTS5 indexes

```bash
npm run build:db
# Output: data/database.db
```

### Step 7: Implement Tools

See [Tool Development Guide](#tool-development-guide) below.

### Step 8: Write Tests

See [Testing Strategy](#testing-strategy) below.

### Step 9: Create Documentation

Required documentation:

- `README.md` - User-facing documentation
- `COVERAGE.md` - What data is included
- `CONTRIBUTING.md` - How to contribute
- `LICENSE` - Apache 2.0

---

## File Reference

### src/index.ts - MCP Server Entry Point

```typescript
/**
 * @fileoverview MCP Server Entry Point
 *
 * This file sets up the Model Context Protocol server and registers
 * all available tools. It handles:
 *
 * 1. Server initialization with stdio transport
 * 2. Database connection (singleton, lazy-loaded)
 * 3. Tool registration (ListTools handler)
 * 4. Tool execution (CallTool handler)
 * 5. Error handling and graceful shutdown
 *
 * @example Running the server
 * ```bash
 * # Direct execution
 * node dist/index.js
 *
 * # Via npm
 * npm start
 *
 * # Development with hot reload
 * npm run dev
 * ```
 */
```

### src/tools/*.ts - Tool Implementations

Each tool file exports:

```typescript
/**
 * @fileoverview [Tool Name] Tool
 *
 * [Description of what this tool does]
 *
 * @example MCP Tool Call
 * ```json
 * {
 *   "name": "tool_name",
 *   "arguments": {
 *     "param1": "value1"
 *   }
 * }
 * ```
 *
 * @example Response
 * ```json
 * {
 *   "field1": "value1"
 * }
 * ```
 */

// Input interface - what the AI provides
export interface ToolInput {
  requiredParam: string;
  optionalParam?: number;
}

// Output interface - what we return
export interface ToolOutput {
  results: ResultItem[];
}

// Main function
export async function toolFunction(
  db: Database,
  input: ToolInput
): Promise<ToolOutput> {
  // Implementation
}
```

### scripts/build-db.ts - Database Builder

```typescript
/**
 * @fileoverview Database Builder Script
 *
 * Builds the SQLite database from seed JSON files. Run this script
 * whenever seed data changes.
 *
 * @example
 * ```bash
 * npm run build:db
 * ```
 *
 * Input:  data/seed/*.json
 * Output: data/database.db
 */
```

### tests/fixtures/test-db.ts - Test Database

```typescript
/**
 * @fileoverview Test Database Fixture
 *
 * Creates an in-memory SQLite database with sample data for testing.
 * This ensures tests are:
 *
 * 1. Fast (in-memory, no disk I/O)
 * 2. Isolated (fresh database per test suite)
 * 3. Reproducible (deterministic sample data)
 *
 * @example Usage in tests
 * ```typescript
 * import { createTestDatabase, closeTestDatabase } from './fixtures/test-db';
 *
 * describe('myTool', () => {
 *   let db: Database;
 *
 *   beforeAll(() => {
 *     db = createTestDatabase();
 *   });
 *
 *   afterAll(() => {
 *     closeTestDatabase(db);
 *   });
 *
 *   it('should work', async () => {
 *     const result = await myTool(db, { ... });
 *     expect(result).toBeDefined();
 *   });
 * });
 * ```
 */
```

---

## Tool Development Guide

### Tool Categories

MCP servers typically need these tool types:

| Category | Purpose | Example |
|----------|---------|---------|
| **Search** | Full-text search across content | `search_regulations` |
| **Get** | Retrieve specific item by ID | `get_article`, `get_statute` |
| **List** | Browse available content | `list_regulations`, `list_chapters` |
| **Compare** | Cross-reference items | `compare_requirements` |
| **Lookup** | Find specific metadata | `get_definition`, `find_case` |
| **Check** | Answer yes/no questions | `check_applicability` |
| **Map** | Cross-framework mappings | `map_to_iso27001` |

### Tool Design Principles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TOOL DESIGN PRINCIPLES                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. SINGLE RESPONSIBILITY                                       â”‚
â”‚     Each tool does one thing well                               â”‚
â”‚                                                                 â”‚
â”‚  2. CLEAR NAMING                                                â”‚
â”‚     verb_noun format: search_statutes, get_article              â”‚
â”‚                                                                 â”‚
â”‚  3. SENSIBLE DEFAULTS                                           â”‚
â”‚     Works without optional parameters                           â”‚
â”‚                                                                 â”‚
â”‚  4. HELPFUL ERRORS                                              â”‚
â”‚     Return null/empty for not found, throw for invalid input    â”‚
â”‚                                                                 â”‚
â”‚  5. RICH OUTPUT                                                 â”‚
â”‚     Include context: article text + chapter + cross-refs        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Search Tool Pattern

```typescript
/**
 * Full-text search tool using SQLite FTS5
 *
 * Features:
 * - BM25 relevance ranking
 * - Snippet extraction with context
 * - Optional filtering by source
 * - Configurable result limit
 */

export interface SearchInput {
  /** Search query (supports AND, OR, NOT, "phrases") */
  query: string;
  /** Filter to specific sources (optional) */
  sources?: string[];
  /** Maximum results to return (default: 10) */
  limit?: number;
}

export interface SearchResult {
  source: string;
  item_id: string;
  title: string;
  /** Snippet with >>>match<<< markers */
  snippet: string;
  /** BM25 relevance score */
  relevance: number;
}

export async function searchContent(
  db: Database,
  input: SearchInput
): Promise<SearchResult[]> {
  const limit = input.limit ?? 10;

  // Escape FTS5 special characters
  const safeQuery = escapeFTS5Query(input.query);

  // Build query with optional source filter
  let sql = `
    SELECT
      source,
      item_id,
      title,
      snippet(content_fts, 3, '>>>', '<<<', '...', 32) as snippet,
      bm25(content_fts) as relevance
    FROM content_fts
    WHERE content_fts MATCH ?
  `;

  const params: any[] = [safeQuery];

  if (input.sources?.length) {
    sql += ` AND source IN (${input.sources.map(() => '?').join(',')})`;
    params.push(...input.sources);
  }

  sql += ` ORDER BY relevance LIMIT ?`;
  params.push(limit);

  return db.prepare(sql).all(...params) as SearchResult[];
}

/** Escape special FTS5 characters */
function escapeFTS5Query(query: string): string {
  // Escape: " ( ) * : ^
  return query.replace(/[\"()*:^]/g, char => `"${char}"`);
}
```

### Get Item Tool Pattern

```typescript
/**
 * Get a specific item by identifier
 *
 * Returns detailed information including:
 * - Full text content
 * - Metadata (dates, sources)
 * - Related items (cross-references)
 */

export interface GetItemInput {
  /** Source identifier (e.g., "GDPR", "BrB") */
  source: string;
  /** Item identifier (e.g., "25", "4:9c") */
  item_id: string;
  /** Include related items? (default: false) */
  include_related?: boolean;
}

export interface Item {
  source: string;
  item_id: string;
  title: string | null;
  text: string;
  parent?: string;  // e.g., chapter
  metadata?: Record<string, string>;
  related?: RelatedItem[];
}

export async function getItem(
  db: Database,
  input: GetItemInput
): Promise<Item | null> {
  const sql = `
    SELECT
      source,
      item_id,
      title,
      text,
      parent,
      metadata,
      related
    FROM items
    WHERE source = ? AND item_id = ?
  `;

  const row = db.prepare(sql).get(input.source, input.item_id) as any;

  if (!row) return null;

  const item: Item = {
    source: row.source,
    item_id: row.item_id,
    title: row.title,
    text: row.text,
    parent: row.parent,
    metadata: row.metadata ? JSON.parse(row.metadata) : undefined,
  };

  if (input.include_related && row.related) {
    item.related = JSON.parse(row.related);
  }

  return item;
}
```

### List Tool Pattern

```typescript
/**
 * List available content with optional filtering
 *
 * Supports:
 * - List all sources
 * - List items within a source
 * - Hierarchical browsing (chapters â†’ sections)
 */

export interface ListInput {
  /** Source to list items from (optional - lists all sources if omitted) */
  source?: string;
  /** Parent item to list children of (e.g., chapter) */
  parent?: string;
}

export interface ListResult {
  sources?: SourceSummary[];
  items?: ItemSummary[];
}

export async function listContent(
  db: Database,
  input: ListInput
): Promise<ListResult> {
  // List all sources
  if (!input.source) {
    const sql = `
      SELECT
        id,
        name,
        COUNT(items.id) as item_count
      FROM sources
      LEFT JOIN items ON items.source = sources.id
      GROUP BY sources.id
    `;
    const sources = db.prepare(sql).all() as SourceSummary[];
    return { sources };
  }

  // List items in source
  let sql = `
    SELECT item_id, title, parent
    FROM items
    WHERE source = ?
  `;
  const params: any[] = [input.source];

  if (input.parent) {
    sql += ` AND parent = ?`;
    params.push(input.parent);
  }

  sql += ` ORDER BY item_id`;

  const items = db.prepare(sql).all(...params) as ItemSummary[];
  return { items };
}
```

### Registering Tools

In `src/index.ts`:

```typescript
// Tool definitions with JSON Schema
const TOOLS: Tool[] = [
  {
    name: 'search_content',
    description: 'Full-text search across all content. Supports boolean operators (AND, OR, NOT) and phrase search with quotes.',
    inputSchema: {
      type: 'object',
      properties: {
        query: {
          type: 'string',
          description: 'Search query'
        },
        sources: {
          type: 'array',
          items: { type: 'string' },
          description: 'Filter to specific sources (optional)'
        },
        limit: {
          type: 'number',
          description: 'Maximum results (default: 10)'
        }
      },
      required: ['query']
    }
  },
  // ... more tools
];

// Register list handler
server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: TOOLS
}));

// Register call handler
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;

  try {
    let result: any;

    switch (name) {
      case 'search_content':
        result = await searchContent(getDb(), args as SearchInput);
        break;
      case 'get_item':
        result = await getItem(getDb(), args as GetItemInput);
        break;
      case 'list_content':
        result = await listContent(getDb(), args as ListInput);
        break;
      default:
        throw new Error(`Unknown tool: ${name}`);
    }

    return {
      content: [{
        type: 'text',
        text: JSON.stringify(result, null, 2)
      }]
    };
  } catch (error) {
    return {
      content: [{
        type: 'text',
        text: `Error: ${(error as Error).message}`
      }],
      isError: true
    };
  }
});
```

---

## Database Design

### Core Tables

Every MCP server needs these fundamental tables:

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CORE TABLES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Sources (regulations, statutes, standards)
CREATE TABLE sources (
  id TEXT PRIMARY KEY,           -- Short ID: "GDPR", "BrB", "ISO27001"
  full_name TEXT NOT NULL,       -- Full name
  source_type TEXT,              -- "regulation", "statute", "standard"
  jurisdiction TEXT,             -- "EU", "SE", "NO", etc.
  identifier TEXT UNIQUE,        -- Official ID: CELEX, SFS number
  effective_date TEXT,           -- ISO 8601 date
  last_amended TEXT,             -- ISO 8601 date
  source_url TEXT                -- Official URL
);

-- Main content items (articles, sections, clauses)
CREATE TABLE items (
  rowid INTEGER PRIMARY KEY,
  source TEXT NOT NULL REFERENCES sources(id),
  item_id TEXT NOT NULL,         -- "1", "4:9c", "A.5.1"
  item_type TEXT,                -- "article", "section", "clause"
  title TEXT,
  text TEXT NOT NULL,
  parent TEXT,                   -- Chapter, part, etc.
  metadata TEXT,                 -- JSON: {effective_from, amended_by, ...}
  related TEXT,                  -- JSON: [{type, source, item_id}, ...]
  UNIQUE(source, item_id)
);

-- Full-text search index
CREATE VIRTUAL TABLE items_fts USING fts5(
  source,
  item_id,
  title,
  text,
  content='items',
  content_rowid='rowid',
  tokenize='unicode61'
);

-- Auto-sync FTS on changes
CREATE TRIGGER items_ai AFTER INSERT ON items BEGIN
  INSERT INTO items_fts(rowid, source, item_id, title, text)
  VALUES (new.rowid, new.source, new.item_id, new.title, new.text);
END;

CREATE TRIGGER items_ad AFTER DELETE ON items BEGIN
  INSERT INTO items_fts(items_fts, rowid, source, item_id, title, text)
  VALUES ('delete', old.rowid, old.source, old.item_id, old.title, old.text);
END;

CREATE TRIGGER items_au AFTER UPDATE ON items BEGIN
  INSERT INTO items_fts(items_fts, rowid, source, item_id, title, text)
  VALUES ('delete', old.rowid, old.source, old.item_id, old.title, old.text);
  INSERT INTO items_fts(rowid, source, item_id, title, text)
  VALUES (new.rowid, new.source, new.item_id, new.title, new.text);
END;
```

### Definitions Table

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- DEFINITIONS
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE TABLE definitions (
  id INTEGER PRIMARY KEY,
  source TEXT NOT NULL REFERENCES sources(id),
  term TEXT NOT NULL,
  definition TEXT NOT NULL,
  defining_item TEXT,            -- Item that defines this term
  UNIQUE(source, term)
);

-- Index for partial matching
CREATE INDEX idx_definitions_term ON definitions(term COLLATE NOCASE);
```

### Cross-Reference Mappings

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CROSS-REFERENCE MAPPINGS
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Map between frameworks (e.g., ISO 27001 â†” GDPR)
CREATE TABLE mappings (
  id INTEGER PRIMARY KEY,
  framework TEXT NOT NULL,       -- "ISO27001", "NIST_CSF"
  control_id TEXT NOT NULL,      -- "A.5.1", "PR.AC-1"
  control_name TEXT,
  target_source TEXT NOT NULL REFERENCES sources(id),
  target_items TEXT NOT NULL,    -- JSON array: ["25", "32"]
  coverage TEXT CHECK(coverage IN ('full', 'partial', 'related')),
  notes TEXT
);

CREATE INDEX idx_mappings_framework ON mappings(framework);
CREATE INDEX idx_mappings_target ON mappings(target_source);
```

### Applicability Rules

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- APPLICABILITY RULES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE TABLE applicability_rules (
  id INTEGER PRIMARY KEY,
  source TEXT NOT NULL REFERENCES sources(id),
  sector TEXT NOT NULL,          -- "financial", "healthcare", etc.
  subsector TEXT,                -- More specific: "banking", "insurance"
  applies INTEGER NOT NULL,      -- 1 = applies, 0 = does not apply
  confidence TEXT CHECK(confidence IN ('definite', 'likely', 'possible')),
  basis_item TEXT,               -- Item that establishes this rule
  conditions TEXT,               -- JSON: additional conditions
  notes TEXT
);

CREATE INDEX idx_applicability_sector ON applicability_rules(sector);
```

### Source Registry

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- SOURCE REGISTRY (for update tracking)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE TABLE source_registry (
  source TEXT PRIMARY KEY REFERENCES sources(id),
  official_id TEXT,              -- CELEX, SFS number
  official_version TEXT,         -- Version identifier
  last_fetched TEXT,             -- ISO 8601 timestamp
  items_expected INTEGER,
  items_parsed INTEGER,
  quality_status TEXT CHECK(quality_status IN ('complete', 'review', 'incomplete')),
  notes TEXT
);
```

---

## Data Ingestion

### Ingestion Script Template

```typescript
#!/usr/bin/env tsx
/**
 * @fileoverview Data Ingestion Script
 *
 * Fetches data from [SOURCE] and converts to seed JSON format.
 *
 * @example Usage
 * ```bash
 * npm run ingest -- <identifier> <output-path>
 * npm run ingest -- "2018:218" data/seed/dataskyddslagen.json
 * ```
 */

import { JSDOM } from 'jsdom';
import * as fs from 'fs';
import * as path from 'path';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONFIGURATION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/** Base URL for data source */
const SOURCE_BASE_URL = 'https://example.com/law/';

/** Known identifiers and their metadata */
const KNOWN_SOURCES: Record<string, SourceMetadata> = {
  '2018:218': {
    id: 'DSL',
    full_name: 'Dataskyddslagen',
    effective_date: '2018-05-25'
  },
  // Add more...
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface SourceMetadata {
  id: string;
  full_name: string;
  effective_date?: string;
}

interface SeedFormat {
  id: string;
  full_name: string;
  identifier: string;
  effective_date?: string;
  source_url: string;
  items: ItemSeed[];
  definitions?: DefinitionSeed[];
}

interface ItemSeed {
  item_id: string;
  title?: string;
  text: string;
  parent?: string;
}

interface DefinitionSeed {
  term: string;
  definition: string;
  defining_item?: string;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MAIN FUNCTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function ingest(identifier: string, outputPath: string): Promise<void> {
  console.log(`\nğŸ“¥ Ingesting: ${identifier}`);

  // 1. Get metadata
  const metadata = KNOWN_SOURCES[identifier];
  if (!metadata) {
    throw new Error(`Unknown identifier: ${identifier}. Add it to KNOWN_SOURCES.`);
  }

  // 2. Fetch HTML
  const url = `${SOURCE_BASE_URL}${encodeURIComponent(identifier)}`;
  console.log(`   Fetching: ${url}`);

  const response = await fetch(url);
  if (!response.ok) {
    throw new Error(`Failed to fetch: ${response.status} ${response.statusText}`);
  }

  const html = await response.text();

  // 3. Parse HTML
  const dom = new JSDOM(html);
  const document = dom.window.document;

  // 4. Extract data
  console.log('   Parsing...');
  const items = extractItems(document);
  const definitions = extractDefinitions(document);

  // 5. Build seed object
  const seed: SeedFormat = {
    id: metadata.id,
    full_name: metadata.full_name,
    identifier: identifier,
    effective_date: metadata.effective_date,
    source_url: url,
    items,
    definitions: definitions.length > 0 ? definitions : undefined
  };

  // 6. Write output
  const outputDir = path.dirname(outputPath);
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  fs.writeFileSync(outputPath, JSON.stringify(seed, null, 2));

  console.log(`\nâœ… Success!`);
  console.log(`   Items: ${items.length}`);
  console.log(`   Definitions: ${definitions.length}`);
  console.log(`   Output: ${outputPath}`);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PARSING FUNCTIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Extract items (articles, sections) from document
 *
 * TODO: Customize this for your data source
 */
function extractItems(document: Document): ItemSeed[] {
  const items: ItemSeed[] = [];

  // Example: extract by CSS selector
  const itemElements = document.querySelectorAll('.article, .section');

  for (const el of itemElements) {
    const item_id = el.getAttribute('data-id') || '';
    const title = el.querySelector('.title')?.textContent?.trim() || undefined;
    const text = el.querySelector('.text')?.textContent?.trim() || '';
    const parent = el.getAttribute('data-chapter') || undefined;

    if (item_id && text) {
      items.push({ item_id, title, text, parent });
    }
  }

  return items;
}

/**
 * Extract definitions from document
 *
 * TODO: Customize this for your data source
 */
function extractDefinitions(document: Document): DefinitionSeed[] {
  const definitions: DefinitionSeed[] = [];

  // Example: extract definition list
  const defElements = document.querySelectorAll('dl.definitions dt, dl.definitions dd');

  let currentTerm: string | null = null;

  for (const el of defElements) {
    if (el.tagName === 'DT') {
      currentTerm = el.textContent?.trim() || null;
    } else if (el.tagName === 'DD' && currentTerm) {
      definitions.push({
        term: currentTerm,
        definition: el.textContent?.trim() || ''
      });
      currentTerm = null;
    }
  }

  return definitions;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CLI
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const args = process.argv.slice(2);

if (args.length < 2) {
  console.error('Usage: npm run ingest -- <identifier> <output-path>');
  console.error('Example: npm run ingest -- "2018:218" data/seed/dataskyddslagen.json');
  process.exit(1);
}

ingest(args[0], args[1]).catch(error => {
  console.error(`\nâŒ Error: ${error.message}`);
  process.exit(1);
});
```

### Build Database Script Template

```typescript
#!/usr/bin/env tsx
/**
 * @fileoverview Database Builder
 *
 * Builds SQLite database from seed JSON files.
 *
 * @example
 * ```bash
 * npm run build:db
 * ```
 */

import Database from 'better-sqlite3';
import * as fs from 'fs';
import * as path from 'path';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONFIGURATION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const SEED_DIR = path.join(__dirname, '../data/seed');
const DB_PATH = path.join(__dirname, '../data/database.db');

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SCHEMA
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const SCHEMA = `
-- Sources
CREATE TABLE sources (
  id TEXT PRIMARY KEY,
  full_name TEXT NOT NULL,
  identifier TEXT UNIQUE,
  effective_date TEXT,
  source_url TEXT
);

-- Items
CREATE TABLE items (
  rowid INTEGER PRIMARY KEY,
  source TEXT NOT NULL REFERENCES sources(id),
  item_id TEXT NOT NULL,
  title TEXT,
  text TEXT NOT NULL,
  parent TEXT,
  metadata TEXT,
  related TEXT,
  UNIQUE(source, item_id)
);

-- FTS5 Index
CREATE VIRTUAL TABLE items_fts USING fts5(
  source, item_id, title, text,
  content='items', content_rowid='rowid',
  tokenize='unicode61'
);

-- FTS Triggers
CREATE TRIGGER items_ai AFTER INSERT ON items BEGIN
  INSERT INTO items_fts(rowid, source, item_id, title, text)
  VALUES (new.rowid, new.source, new.item_id, new.title, new.text);
END;

CREATE TRIGGER items_ad AFTER DELETE ON items BEGIN
  INSERT INTO items_fts(items_fts, rowid, source, item_id, title, text)
  VALUES ('delete', old.rowid, old.source, old.item_id, old.title, old.text);
END;

-- Definitions
CREATE TABLE definitions (
  id INTEGER PRIMARY KEY,
  source TEXT NOT NULL REFERENCES sources(id),
  term TEXT NOT NULL,
  definition TEXT NOT NULL,
  defining_item TEXT,
  UNIQUE(source, term)
);

-- Source Registry
CREATE TABLE source_registry (
  source TEXT PRIMARY KEY,
  official_id TEXT,
  last_fetched TEXT,
  items_expected INTEGER,
  items_parsed INTEGER,
  quality_status TEXT
);
`;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BUILD FUNCTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function buildDatabase(): void {
  console.log('ğŸ—ï¸  Building database...\n');

  // Delete existing database
  if (fs.existsSync(DB_PATH)) {
    fs.unlinkSync(DB_PATH);
    console.log('   Deleted existing database');
  }

  // Create new database
  const db = new Database(DB_PATH);

  // Enable foreign keys
  db.pragma('foreign_keys = ON');

  // Create schema
  db.exec(SCHEMA);
  console.log('   Created schema');

  // Load seed files
  const seedFiles = fs.readdirSync(SEED_DIR)
    .filter(f => f.endsWith('.json') && !f.startsWith('.'));

  console.log(`\nğŸ“‚ Loading ${seedFiles.length} seed files...\n`);

  // Prepare statements
  const insertSource = db.prepare(`
    INSERT INTO sources (id, full_name, identifier, effective_date, source_url)
    VALUES (?, ?, ?, ?, ?)
  `);

  const insertItem = db.prepare(`
    INSERT INTO items (source, item_id, title, text, parent, metadata, related)
    VALUES (?, ?, ?, ?, ?, ?, ?)
  `);

  const insertDefinition = db.prepare(`
    INSERT INTO definitions (source, term, definition, defining_item)
    VALUES (?, ?, ?, ?)
  `);

  const insertRegistry = db.prepare(`
    INSERT INTO source_registry (source, official_id, last_fetched, items_expected, items_parsed, quality_status)
    VALUES (?, ?, ?, ?, ?, ?)
  `);

  // Process each seed file
  let totalItems = 0;
  let totalDefinitions = 0;

  for (const file of seedFiles) {
    const filePath = path.join(SEED_DIR, file);
    const seed = JSON.parse(fs.readFileSync(filePath, 'utf-8'));

    // Insert source
    insertSource.run(
      seed.id,
      seed.full_name,
      seed.identifier,
      seed.effective_date,
      seed.source_url
    );

    // Insert items
    for (const item of seed.items || []) {
      insertItem.run(
        seed.id,
        item.item_id,
        item.title,
        item.text,
        item.parent,
        item.metadata ? JSON.stringify(item.metadata) : null,
        item.related ? JSON.stringify(item.related) : null
      );
      totalItems++;
    }

    // Insert definitions
    for (const def of seed.definitions || []) {
      insertDefinition.run(
        seed.id,
        def.term,
        def.definition,
        def.defining_item
      );
      totalDefinitions++;
    }

    // Insert registry
    insertRegistry.run(
      seed.id,
      seed.identifier,
      new Date().toISOString(),
      seed.items?.length || 0,
      seed.items?.length || 0,
      'complete'
    );

    console.log(`   âœ“ ${seed.id}: ${seed.items?.length || 0} items, ${seed.definitions?.length || 0} definitions`);
  }

  db.close();

  console.log(`\nâœ… Database built successfully!`);
  console.log(`   Total items: ${totalItems}`);
  console.log(`   Total definitions: ${totalDefinitions}`);
  console.log(`   Output: ${DB_PATH}`);
}

// Run
buildDatabase();
```

---

## Testing Strategy

### Test Database Fixture

```typescript
/**
 * @fileoverview Test Database Fixture
 *
 * Creates an in-memory database with sample data for testing.
 */

import Database from 'better-sqlite3';

// Sample data for tests
const SAMPLE_SOURCES = [
  { id: 'SOURCE1', full_name: 'Test Source 1', identifier: 'TEST-001' },
  { id: 'SOURCE2', full_name: 'Test Source 2', identifier: 'TEST-002' }
];

const SAMPLE_ITEMS = [
  { source: 'SOURCE1', item_id: '1', title: 'First Item', text: 'This is the first test item with searchable content.', parent: 'Chapter I' },
  { source: 'SOURCE1', item_id: '2', title: 'Second Item', text: 'This is the second test item about data protection.', parent: 'Chapter I' },
  { source: 'SOURCE2', item_id: '1', title: 'Another Item', text: 'Different source item about security requirements.', parent: null }
];

const SAMPLE_DEFINITIONS = [
  { source: 'SOURCE1', term: 'test term', definition: 'A term used for testing purposes', defining_item: '1' },
  { source: 'SOURCE2', term: 'security', definition: 'Protection against threats', defining_item: '1' }
];

export function createTestDatabase(): Database.Database {
  const db = new Database(':memory:');

  // Create schema (same as production)
  db.exec(`
    CREATE TABLE sources (
      id TEXT PRIMARY KEY,
      full_name TEXT NOT NULL,
      identifier TEXT UNIQUE
    );

    CREATE TABLE items (
      rowid INTEGER PRIMARY KEY,
      source TEXT NOT NULL,
      item_id TEXT NOT NULL,
      title TEXT,
      text TEXT NOT NULL,
      parent TEXT,
      UNIQUE(source, item_id)
    );

    CREATE VIRTUAL TABLE items_fts USING fts5(
      source, item_id, title, text,
      content='items', content_rowid='rowid'
    );

    CREATE TRIGGER items_ai AFTER INSERT ON items BEGIN
      INSERT INTO items_fts(rowid, source, item_id, title, text)
      VALUES (new.rowid, new.source, new.item_id, new.title, new.text);
    END;

    CREATE TABLE definitions (
      id INTEGER PRIMARY KEY,
      source TEXT NOT NULL,
      term TEXT NOT NULL,
      definition TEXT NOT NULL,
      defining_item TEXT
    );
  `);

  // Insert sample data
  const insertSource = db.prepare('INSERT INTO sources VALUES (?, ?, ?)');
  for (const s of SAMPLE_SOURCES) {
    insertSource.run(s.id, s.full_name, s.identifier);
  }

  const insertItem = db.prepare('INSERT INTO items (source, item_id, title, text, parent) VALUES (?, ?, ?, ?, ?)');
  for (const i of SAMPLE_ITEMS) {
    insertItem.run(i.source, i.item_id, i.title, i.text, i.parent);
  }

  const insertDef = db.prepare('INSERT INTO definitions (source, term, definition, defining_item) VALUES (?, ?, ?, ?)');
  for (const d of SAMPLE_DEFINITIONS) {
    insertDef.run(d.source, d.term, d.definition, d.defining_item);
  }

  return db;
}

export function closeTestDatabase(db: Database.Database): void {
  db.close();
}
```

### Test File Template

```typescript
/**
 * @fileoverview Tests for [Tool Name]
 */

import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import type { Database } from 'better-sqlite3';
import { createTestDatabase, closeTestDatabase } from '../fixtures/test-db';
import { toolFunction, ToolInput } from '../../src/tools/tool-name';

describe('toolFunction', () => {
  let db: Database;

  beforeAll(() => {
    db = createTestDatabase();
  });

  afterAll(() => {
    closeTestDatabase(db);
  });

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Happy Path Tests
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  it('should return results for valid input', async () => {
    const input: ToolInput = { query: 'test' };
    const result = await toolFunction(db, input);

    expect(result).toBeDefined();
    expect(result.length).toBeGreaterThan(0);
  });

  it('should filter by source when specified', async () => {
    const input: ToolInput = { query: 'test', sources: ['SOURCE1'] };
    const result = await toolFunction(db, input);

    expect(result.every(r => r.source === 'SOURCE1')).toBe(true);
  });

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Edge Cases
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  it('should return empty array for no matches', async () => {
    const input: ToolInput = { query: 'nonexistent' };
    const result = await toolFunction(db, input);

    expect(result).toEqual([]);
  });

  it('should handle special characters in query', async () => {
    const input: ToolInput = { query: 'test (with) "special" chars' };
    const result = await toolFunction(db, input);

    // Should not throw, may return empty
    expect(Array.isArray(result)).toBe(true);
  });

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Limit and Pagination
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  it('should respect limit parameter', async () => {
    const input: ToolInput = { query: 'test', limit: 1 };
    const result = await toolFunction(db, input);

    expect(result.length).toBeLessThanOrEqual(1);
  });

  it('should use default limit when not specified', async () => {
    const input: ToolInput = { query: 'test' };
    const result = await toolFunction(db, input);

    expect(result.length).toBeLessThanOrEqual(10); // Default limit
  });
});
```

### Vitest Configuration

```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    include: ['tests/**/*.test.ts'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'html'],
      include: ['src/**/*.ts'],
      exclude: ['src/index.ts']  // Entry point tested via integration
    }
  }
});
```

---

## Deployment

### Package.json Scripts

```json
{
  "name": "@ansvar/your-mcp-server",
  "version": "0.1.0",
  "description": "MCP server for [Your Content]",
  "type": "module",
  "main": "dist/index.js",
  "bin": {
    "your-mcp-server": "dist/index.js"
  },
  "files": [
    "dist",
    "data/database.db"
  ],
  "scripts": {
    "build": "tsc",
    "build:db": "tsx scripts/build-db.ts",
    "dev": "tsx src/index.ts",
    "start": "node dist/index.js",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "ingest": "tsx scripts/ingest-source.ts",
    "check-updates": "tsx scripts/check-updates.ts",
    "lint": "eslint src tests",
    "prepublishOnly": "npm run build"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.25.3",
    "better-sqlite3": "^12.6.2"
  },
  "devDependencies": {
    "@types/better-sqlite3": "^7.6.14",
    "@types/node": "^22.15.29",
    "jsdom": "^27.4.0",
    "tsx": "^4.21.0",
    "typescript": "^5.9.3",
    "vitest": "^4.0.18"
  },
  "engines": {
    "node": ">=18"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/ansvar-systems/your-mcp-server"
  },
  "keywords": ["mcp", "compliance", "ansvar"],
  "author": "Ansvar Systems AB",
  "license": "Apache-2.0"
}
```

### Dockerfile

```dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Multi-stage Dockerfile for MCP Server
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Stage 1: Build TypeScript
FROM node:20-alpine AS builder

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci

# Copy source and build
COPY tsconfig.json ./
COPY src ./src
RUN npm run build

# Stage 2: Production image
FROM node:20-alpine AS production

WORKDIR /app

# Install production dependencies only
COPY package*.json ./
RUN npm ci --omit=dev && \
    # Rebuild native modules for Alpine
    npm rebuild better-sqlite3

# Copy built files
COPY --from=builder /app/dist ./dist

# Copy pre-built database
COPY data/database.db ./data/database.db

# Create non-root user
RUN addgroup -S nodejs && adduser -S nodejs -G nodejs
USER nodejs

# Environment
ENV NODE_ENV=production

# Entry point
CMD ["node", "dist/index.js"]
```

### GitHub Actions Workflow

```yaml
# .github/workflows/publish.yml
name: Publish to npm

on:
  push:
    tags:
      - 'v*'

jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # For npm provenance

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          registry-url: 'https://registry.npmjs.org'

      - name: Install dependencies
        run: npm ci --ignore-scripts

      - name: Build
        run: npm run build

      - name: Test
        run: npm test

      - name: Publish
        run: npm publish --access public --provenance
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}
```

### Smithery Configuration

```yaml
# smithery.yaml
name: your-mcp-server
description: MCP server for [Your Content]
version: "0.1.0"

runtime: node
entrypoint: dist/index.js

transport:
  type: stdio

metadata:
  author: Ansvar Systems AB
  license: Apache-2.0
  homepage: https://github.com/ansvar-systems/your-mcp-server
  tags:
    - compliance
    - legal
    - ansvar
```

---

## Checklist

### New Server Setup Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEW SERVER CHECKLIST                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  INITIALIZATION                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  [ ] Copy skeleton to new directory                             â”‚
â”‚  [ ] Update package.json (name, description, repository)        â”‚
â”‚  [ ] Initialize git repository                                  â”‚
â”‚  [ ] Create GitHub repository                                   â”‚
â”‚                                                                 â”‚
â”‚  DATA MODELING                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  [ ] Define data entities and relationships                     â”‚
â”‚  [ ] Design database schema in build-db.ts                      â”‚
â”‚  [ ] Create seed JSON format specification                      â”‚
â”‚  [ ] Document data sources                                      â”‚
â”‚                                                                 â”‚
â”‚  DATA INGESTION                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  [ ] Implement ingest script for data source                    â”‚
â”‚  [ ] Test ingestion with sample data                            â”‚
â”‚  [ ] Ingest all required data                                   â”‚
â”‚  [ ] Build database and verify                                  â”‚
â”‚                                                                 â”‚
â”‚  TOOL DEVELOPMENT                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  [ ] Implement search tool                                      â”‚
â”‚  [ ] Implement get-item tool                                    â”‚
â”‚  [ ] Implement list tool                                        â”‚
â”‚  [ ] Implement domain-specific tools                            â”‚
â”‚  [ ] Register all tools in index.ts                             â”‚
â”‚                                                                 â”‚
â”‚  TESTING                                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚  [ ] Create test database fixture with sample data              â”‚
â”‚  [ ] Write tests for each tool                                  â”‚
â”‚  [ ] Achieve >80% code coverage                                 â”‚
â”‚  [ ] Test with MCP Inspector                                    â”‚
â”‚                                                                 â”‚
â”‚  DOCUMENTATION                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  [ ] Write README.md with installation instructions             â”‚
â”‚  [ ] Document all tools with examples                           â”‚
â”‚  [ ] Create COVERAGE.md listing included data                   â”‚
â”‚  [ ] Add CONTRIBUTING.md guidelines                             â”‚
â”‚  [ ] Include LICENSE file (Apache 2.0)                          â”‚
â”‚                                                                 â”‚
â”‚  DEPLOYMENT                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  [ ] Create Dockerfile                                          â”‚
â”‚  [ ] Create smithery.yaml                                       â”‚
â”‚  [ ] Set up GitHub Actions workflow                             â”‚
â”‚  [ ] Configure npm publishing                                   â”‚
â”‚                                                                 â”‚
â”‚  LAUNCH                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚  [ ] Publish to npm                                             â”‚
â”‚  [ ] Push to Docker Hub                                         â”‚
â”‚  [ ] Submit to Smithery                                         â”‚
â”‚  [ ] Submit to Glama                                            â”‚
â”‚  [ ] Create PR for awesome-mcp-servers                          â”‚
â”‚  [ ] Announce on LinkedIn                                       â”‚
â”‚  [ ] Post on r/mcp                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Appendix: Quick Reference

### Common SQL Patterns

```sql
-- Full-text search with BM25 ranking
SELECT *, bm25(items_fts) as score
FROM items_fts
WHERE items_fts MATCH ?
ORDER BY score
LIMIT ?;

-- Snippet extraction
SELECT snippet(items_fts, 3, '>>>', '<<<', '...', 32) as snippet
FROM items_fts
WHERE items_fts MATCH ?;

-- Get item with parsed JSON
SELECT *, json_extract(metadata, '$.effective_date') as effective
FROM items
WHERE source = ? AND item_id = ?;

-- Count items by source
SELECT source, COUNT(*) as count
FROM items
GROUP BY source;
```

### Common TypeScript Patterns

```typescript
// Null-safe JSON parsing
const metadata = row.metadata
  ? JSON.parse(row.metadata)
  : null;

// Array from optional input
const sources = input.sources ?? [];

// Default limit
const limit = input.limit ?? 10;

// Build dynamic WHERE clause
const conditions: string[] = [];
const params: any[] = [];

if (input.source) {
  conditions.push('source = ?');
  params.push(input.source);
}

const where = conditions.length
  ? `WHERE ${conditions.join(' AND ')}`
  : '';
```

### MCP Tool Schema Reference

```typescript
// String parameter
{
  type: 'string',
  description: 'Description of parameter'
}

// Number parameter
{
  type: 'number',
  description: 'Description'
}

// Boolean parameter
{
  type: 'boolean',
  description: 'Description'
}

// Array of strings
{
  type: 'array',
  items: { type: 'string' },
  description: 'Description'
}

// Enum (limited values)
{
  type: 'string',
  enum: ['option1', 'option2', 'option3'],
  description: 'Description'
}
```

---

<p align="center">
<strong>Ansvar Systems AB</strong><br>
Building the compliance infrastructure for Nordic AI<br>
<a href="https://ansvar.ai">ansvar.ai</a>
</p>
